# Speaker_GPT_Follower

## Project Overview
This project enhances the "Speaker Follower Models for Vision and Language Navigation" by incorporating OpenAI's GPT models to refine navigation instructions generated by the speaker model before their interpretation by the follower model. Our focus is on evaluating how advanced natural language processing can elevate the quality of navigation instructions, thereby enhancing the performance of follower models in Vision and Language Navigation (VLN) scenarios.

## Features
- **Instruction Refinement**: Using OpenAI's GPT models to enhance navigation instructions from the speaker model for clarity and ease of navigation.
- **Parallel Processing**: Employs multithreading to expedite the refinement process, ensuring efficiency in handling large sets of instructions.
- **Enhanced Navigation Performance**: Evaluates the follower model's performance with both original and GPT-refined instructions, highlighting improvements in navigation accuracy.
- **Model Comparison**: Offers a framework for comparing the effectiveness of different GPT models and refinement prompts in enhancing instruction quality.
- **Error Handling and Logging**: Implements robust error handling and detailed logging to monitor the refinement process and ensure data integrity.

## Usage
The project consists of steps where the initial instructions are created by the speaker model, refined by the GPT model, and then assessed using the follower model. The main script manages the process based on GPT and is adaptable for testing various GPT models and prompts.

## Technologies and Learning

- **OpenAI API**: Central to integrating GPT models for the instruction refinement process.
- **Python**: The primary programming language used for scripting the instruction refinement and evaluation processes.
- **Concurrent Futures**: Facilitates multithreading to improve the efficiency of the GPT refinement process.
- **Anaconda**: Used for managing project environments and dependencies, enabling smooth development and testing across different computational setups.
- **Computational Shared Facility**: Leveraged the university's computational resources for processing large datasets and running intensive models.
- **PyTorch Libraries**: Explored and utilised PyTorch-related libraries for updating and managing model-related code.
- **OpenCV Libraries**:  Investigated the OpenCV library to update any outdated functions that were causing issues.
- **Logging**: Utilised for tracking the process flow and identifying potential issues during the instruction refinement stage.
- **JSON**: Employed for handling the instruction data, enabling seamless integration between the speaker model, GPT refinement, and follower model.


## Acknowledgments
- Ronghang Hu and contributors for the foundational "Speaker-Follower Models for Vision-and-Language Navigation" repository (https://github.com/ronghanghu/speaker_follower).
- OpenAI for the GPT models that significantly enhance the instruction refinement process.
